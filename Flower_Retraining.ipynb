{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.3.1\n",
      "Hub version: 0.10.0\n",
      "WARNING:tensorflow:From <ipython-input-1-0831fa394ed3>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4 with input size (224, 224)\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2_100_224\", 224)\n",
    "handle_base, pixels = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
    "\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731 images belonging to 5 classes.\n",
      "Found 2936 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "                   interpolation=\"bilinear\")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
    "\n",
    "do_data_augmentation = False\n",
    "if do_data_augmentation:\n",
    "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      horizontal_flip=True,\n",
    "      width_shift_range=0.2, height_shift_range=0.2,\n",
    "      shear_range=0.2, zoom_range=0.2,\n",
    "      **datagen_kwargs)\n",
    "else:\n",
    "  train_datagen = valid_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fine_tuning = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 6405      \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "91/91 [==============================] - 28s 305ms/step - loss: 0.9613 - accuracy: 0.7404 - val_loss: 0.7548 - val_accuracy: 0.8423\n",
      "Epoch 2/5\n",
      "91/91 [==============================] - 27s 297ms/step - loss: 0.6932 - accuracy: 0.8826 - val_loss: 0.7231 - val_accuracy: 0.8537\n",
      "Epoch 3/5\n",
      "91/91 [==============================] - 27s 301ms/step - loss: 0.6552 - accuracy: 0.8950 - val_loss: 0.6814 - val_accuracy: 0.8736\n",
      "Epoch 4/5\n",
      "91/91 [==============================] - 27s 297ms/step - loss: 0.6330 - accuracy: 0.9087 - val_loss: 0.7100 - val_accuracy: 0.8480\n",
      "Epoch 5/5\n",
      " 5/91 [>.............................] - ETA: 16s - loss: 0.6154 - accuracy: 0.9312"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_string_from_index(index):\n",
    "   for class_string, class_index in valid_generator.class_indices.items():\n",
    "      if class_index == index:\n",
    "         return class_string\n",
    "\n",
    "x, y = next(valid_generator)\n",
    "image = x[0, :, :, :]\n",
    "true_index = np.argmax(y[0])\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
    "prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
    "predicted_index = np.argmax(prediction_scores)\n",
    "print(\"True label: \" + get_class_string_from_index(true_index))\n",
    "print(\"Predicted label: \" + get_class_string_from_index(predicted_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flower.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(valid_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classlist.txt', 'w') as filehandle:\n",
    "    for listitem in list(valid_generator.class_indices.keys()):\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
